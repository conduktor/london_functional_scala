= When stateless APIs are not enough: deep dive into a  streaming backend design

{localdate} - Luc Duzan & Matthieu Baechler

:revealjs_hash: true
:revealjs_slideNumber: true
:revealjs_fragmentInURL: true
:imagesdir: ./images
:sourcedir: ../src/main/scala

<<<
[.columns]
== Who are we?

[.column]
--
image::luc.jpg[width=200]

Luc Duzan

 * Software Engineer @ Conduktor
 * Bike enthusiast 🚲
 * @strokyl on twitter
--

[.column]
--
image::matthieu.jpg[width=200]

Matthieu Baechler

 * Older Software Engineer @ Conduktor
 * Free Software enthusiat
 * @m_baechler on twitter
--


<<<
== ⚠️ Disclaimers

 * We are going to speak about UX
 * This design is not new

<<<
== We are Conduktor

image::conduktor.png[]

<<<
== A few facts & metrics about Kafka

* Kafka is built to be fast at publishing and consuming messages
* Scale can be massive
  - ~ 1 000 topics
  - ~ 100 000 partitions
  - ~ millions of messages per second
* Not so fast at providing insights about your data and your cluster

<<<
== What Conduktor console looks like


image::conduktor-console.png[]

<<<
== What’s behind this screen

image::dependency-graph.png[]

<<<
== Solution 1: Single request

We have GraphQL, let’s load everything (20 topics) at once for our screen

image::graphql.png[]

<<<
== Solution 2: Query in two steps

What about loading all topic names then query details for displayed topics?

image::split-graphql.png[]

<<<
== API granularity

What about loading all topic names then query details for displayed topics?

FIXME

image::granularity.png[]

<<<
== Solution 3: Streaming design

image::streaming.png[]

<<<
== Streaming design: tapir endpoint definition

[source,scala]
----
trait TopicInfoStreamService {
 def streamInfos: ZStream[Any, Throwable, Info]
}

val infos = endpoint.get
 .in("streaming")
 .errorOut(jsonBody[ErrorInfo])
 .out(serverSentEventsBody)
 .zServerLogic(_ =>
   ZIO.succeed(topicInfoStreamService.streamInfos.map { info =>
     ServerSentEvent(data = Some(info.asJson.spaces2))
   })
 )
----

<<<
== Streaming design: ADT

[source,scala]
----
sealed trait Info

case object Complete                                                              extends Info
case class Topics(topics: Set[TopicName])                                         extends Info
case class Size(topicName: TopicName, size: TopicSize)                            extends Info
case class RecordCountInfo(topicName: TopicName, count: RecordCount)              extends Info
case class PartitionInfo(topicName: TopicName, partition: Partition)              extends Info
case class ReplicationFactorInfo(topicName: TopicName, factor: RepFactor)         extends Info
case class SpreadInfo(topicName: TopicName, spread: Spread)                       extends Info
----

<<<
== Streaming design: service implementation

[source,scala]
----
def streamInfos: Stream[Info] =
 streamThings { queue =>
   for {
     names <- kafkaService.listTopicNames.map(_.toSet).tap(queue.sendNames)

     brokerIds  <- kafkaService.getBrokerIds
     brokerCount = BrokerCount(brokerIds.length)

     _ <- kafkaService.getTopicSize(brokerIds).forEachZIO(queue.sendSizes)

     _ <- describeTopics(names.toList)
            .tap(queue.sendSpreadPartitionAndReplicationFactor(brokerCount))
            .viaFunction(countRecordForPartitions)
            .tap(queue.sendRecordCount)
            .runDrain

     _ <- queue.complete
   } yield ()
 }
----

<<<
== Key takeaways

* Streaming endpoint:
  - no trade off between latency and overall runtime
  - Make frontend code simple
  - Simple to implement in backend part

<<<
== What’s next?

After loading the list of topics, what is the user going to do next?

image::one-does-not.png[]

<<<
== Why not prefetch on frontend

FIXME

<<<
== We now have a stateful backend

* We need to keep a state between “requests”
* Bind the state lifetime with the client connection

<<<
== Long living stream + commands

image::streaming-1.png[]

<<<
== Long living stream + commands

image::streaming-2.png[]

<<<
== How to handle state in streams: mapAccum(ZIO)

FIXME


<<<
=== How to handle state in streams: mapAccum(ZIO)

image::streaming-3.png[]

<<<
== Step by step execution
Command: Subscribe

[cols="a, a, a"]
|===
|State |Requests |Output

|[.pre-wrap]
{
  Topics = #Loading#,
  BrokerIds = Loading,
  Descriptions = {}
}
|
[source,hocon]
----
[
  ListTopics,
  ListBrokers
]
----
|
[source,hocon]
----
Nil
----
|===

<<<
=== Step by step execution

Command: TopicNames [foo, bar]

[.columns]
[.column]
State

[source,hocon]
----
{
  Topics = [foo, bar],
  BrokerIds = Loading,
  Descriptions =
    { foo = Loading
    , bar = Loading
    }
}
----

Requests

[source,hocon]
----
[
  ListBrokers,
  DescribeTopics[foo, bar]
]
----

Output
[source,hocon]
----
[
  TopicNames[foo, bar]
]
----


<<<
=== Step by step execution

Command: Topics description for [foo, bar]

[.columns]
[.column]
State

[source,hocon]
----
{
  Topics = [foo, bar],
  BrokerIds = [b1, b2],
  Descriptions =
    { foo:
      { partitions: 3,
        replicationFactor: 3}
    , bar:
      { partitions: 2,
        replicationFactor: 3}
    }
}
----

Requests

[source,hocon]
----
[
  DescribeLogDirs[b1, b2],
  ListBeginOffset[
     foo-1, foo-2, foo-3,
     bar-1, bar-2],
  ListEndOffset[
     foo-1, foo-2, foo-3,
     bar-1, bar-2],
]
----

Output
[source,hocon]
----
[
  ReplicationFactor(foo, 3),
  Partition(foo, 3),
  Spread(foo, 1),
  ReplicationFactor(foo, 3),
  Partition(foo, 2),
  Spread(foo, 1),
]
----

<<<
=== Streaming “loop”

image::streaming-4.png[]

<<<
=== Stateful Streaming design

[source,scala]
----
def streamInfos(queue: Queue[Input.Command]): Stream[Info] =
 ZStream
   .unwrap(for {
     responsesQueue       <- Queue.unbounded[Input.Response]
     inputs: Stream[Input] = ZStream.mergeAllUnbounded(
                                         ZStream.fromQueue(queue),
                                         ZStream.fromQueue(responsesQueue))
   } yield {
     inputs
       .mapAccumZIO(State.empty) { (state, input) =>
         val (stateUpdatedWithInput, diff) = applyInput(state, input)
         val requests                      = nextRequests(stateUpdatedWithInput, diff)
         val updatedState                  = applyRequests(stateUpdatedWithInput, requests)
         val infos                         = toInfo(updatedState, diff)
         executeRequests(responsesQueue)(requests).as((updatedState, infos))
       }
   })
----

<<<
=== Stateful streaming design: sum up

* State lifetime is simply linked to stream lifetime
* We can cleany delegate the implementation of business logic in three pure functions:
  - updateState: user command/response from external resource => new state
  - nextCommand: state => commands to perform on external system
  - frontendView: state diff => informations to send to frontend

<<<
=== When not to use that

* CQRS
* Your datasource is fast anyway

<<<
== Takeaways

image::takeaway-0.png[]

<<<
=== Takeaways

image::takeaway-1.png[]

<<<
=== Takeaways

image::takeaway-2.png[]

<<<
=== Takeaways

image::takeaway-0.png[]
image::takeaway-1.png[]
image::takeaway-2.png[]

<<<
== Resources

https://github.com/conduktor/scalaIO_2022

image::qrcode.png[]


[.questions]
=== !
